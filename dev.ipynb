{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import gsplat\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from src.model.gaussians import Gaussians\n",
    "from src.data.colmap import ColmapDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/media/jip/T7/thesis/code/data/'\n",
    "if not os.path.isdir(ROOT_DIR):\n",
    "    ROOT_DIR = '/home/jip/data1/'\n",
    "ROOT_DIR += \"bicycle\"\n",
    "\n",
    "DEVICE = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "try:\n",
    "    torch.cuda.set_device(DEVICE)\n",
    "except:\n",
    "    print(\"!WARNING! could not set cuda device, falling back to default\")\n",
    "\n",
    "LOAD_CKPT = None\n",
    "# LOAD_CKPT = \"models/model_tue23jan1434.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_path_to_tensor(image_path:str):\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    transform = transforms.ToTensor()\n",
    "    img_tensor = transform(img).permute(1, 2, 0)[..., :3]\n",
    "    return img_tensor\n",
    "\n",
    "def tensor_to_ndarray(image:torch.Tensor) -> np.ndarray:\n",
    "    return image.detach().cpu().numpy()\n",
    "\n",
    "def ndarray_to_Image(image:np.ndarray) -> Image.Image:\n",
    "    return Image.fromarray((image*255).astype(np.uint8))\n",
    "\n",
    "def tensor_to_Image(image:torch.Tensor) -> Image.Image:\n",
    "    return ndarray_to_Image(tensor_to_ndarray(image))\n",
    "\n",
    "\n",
    "def train(\n",
    "    model:Gaussians,\n",
    "    dataset:ColmapDataSet,\n",
    "    device=DEVICE,\n",
    "    num_iterations:int = 7_000,\n",
    "    lr: float = 0.01\n",
    ") -> tuple[Gaussians,dict]:\n",
    "\n",
    "    # Set up optimizer\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    # Output package\n",
    "    out = {\n",
    "        'losses':[],\n",
    "        'lr':[]\n",
    "    }\n",
    "\n",
    "    # Use progress bar\n",
    "    num_data = len(dataset)\n",
    "    pbar = tqdm(total=num_iterations, desc=\"Training\", smoothing=.5)\n",
    "\n",
    "    save_every = 1\n",
    "    save_at = '_DSC8680.JPG'\n",
    "    test_cam = dataset.cameras[1]\n",
    "    # camera = dataset.cameras[1]\n",
    "    # tensor_to_Image(camera.gt_image).save(f'renders/gt_{camera.name}')\n",
    "\n",
    "    # Set up epoch\n",
    "    loss_accum=0.\n",
    "    loss_norm=0\n",
    "\n",
    "    dataset_cycle = dataset.cycle()\n",
    "\n",
    "    for iter in range(1,num_iterations+1):\n",
    "\n",
    "        camera = next(dataset_cycle)\n",
    "\n",
    "        # Forward pass\n",
    "        camera.to(device)\n",
    "        rendering = model.render(camera)\n",
    "        loss = loss_fn(rendering, camera.gt_image)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Densify\n",
    "        model.update_densification_stats()\n",
    "        if iter >= 1_000 and iter%100 == 0:\n",
    "            model.densify()\n",
    "\n",
    "        # Update batch info\n",
    "        loss_accum += loss.item()\n",
    "        loss_norm += 1\n",
    "\n",
    "        if iter%10 == 0:\n",
    "            # Compute epoch loss\n",
    "            _loss = loss_accum / loss_norm\n",
    "            _lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "            out['losses'].append(_loss)\n",
    "            out['lr'].append(_lr)\n",
    "            loss_accum = 0.\n",
    "            loss_norm = 0\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss':f\"{_loss:.2e}\",\n",
    "                'lr':f\"{_lr:.1e}\",\n",
    "                '#splats': model.num_points,\n",
    "            }, refresh=False)\n",
    "            pbar.update(10)\n",
    "\n",
    "        # End iter\n",
    "        camera.to('cpu')\n",
    "\n",
    "        if (iter-1)%100 == 0:\n",
    "            test_cam.to(device)\n",
    "            # tensor_to_Image(model.render(camera, bg=torch.zeros(3,device=device))).save(f'renders/epoch{epoch}_{camera.name}')\n",
    "            tensor_to_Image(model.render(test_cam, bg=torch.zeros(3,device=device))).save(f'renders/latest_{test_cam.name}')\n",
    "            test_cam.to('cpu')\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "    return model, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cameras...\n",
      "Reading images...\n",
      "Parsing cameras and images...\n",
      "(194, 3)\n",
      "Found 194 cameras\n"
     ]
    }
   ],
   "source": [
    "dataset = ColmapDataSet(\n",
    "    root_dir=ROOT_DIR,\n",
    "    img_folder='images_4',\n",
    ")\n",
    "\n",
    "dataset.cameras = sorted(dataset.cameras, key=lambda cam:cam.name)\n",
    "\n",
    "print(f\"Found {len(dataset)} cameras\")\n",
    "assert len(dataset)>0,f\"Could not find any cameras, root dir is {ROOT_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55933\n"
     ]
    }
   ],
   "source": [
    "model = Gaussians.from_colmap(\n",
    "    path_to_points3D_file=os.path.join(ROOT_DIR,'sparse/0/points3D.txt'),\n",
    "    device=DEVICE,\n",
    "    grad_threshold=5e-8,\n",
    "    max_scale=dataset.scene_extend * 0.01\n",
    ")\n",
    "print(model.num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcd5ee44fd0434583a9341ae892fd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LOAD_CKPT \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     model,out \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataset, device, num_iterations, lr)\u001b[0m\n\u001b[1;32m     67\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Densify\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_densification_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1_000\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     72\u001b[0m     model\u001b[38;5;241m.\u001b[39mdensify()\n",
      "File \u001b[0;32m~/novel-viewpoint-synthesis/src/model/gaussians.py:321\u001b[0m, in \u001b[0;36mGaussians.update_densification_stats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# Update running average of visible Gaussians\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_xys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_xys\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xys_grad[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_visible] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_xys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_visible]\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xys_grad_norm[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_visible] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# Update max radii\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "if LOAD_CKPT is None:\n",
    "    model,out = train(\n",
    "        model,\n",
    "        dataset,\n",
    "        num_iterations=7_000,\n",
    "        lr=0.01,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(out['losses'])\n",
    "    plt.ylim(0)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss plot training\")\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(out['lr'])\n",
    "    # plt.ylim(0)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning rate\")\n",
    "    plt.title(\"Learning rate plot training\")\n",
    "\n",
    "    plt.show()\n",
    "    fname = \"models/model_{}.ckpt\".format(datetime.datetime.now().strftime('%a%d%b%H%M').lower())\n",
    "    # torch.save(model.state_dict(),fname)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(LOAD_CKPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Not now\")\n",
    "print(\"Saving results..\")\n",
    "out_dir = os.path.join(os.getcwd(), \"renders\")\n",
    "\n",
    "rendering = []\n",
    "nrow = len(dataset)\n",
    "\n",
    "cameras = sorted(dataset, key=lambda cam:cam.name)\n",
    "\n",
    "for camera in cameras:\n",
    "\n",
    "    camera.to(DEVICE)\n",
    "    bg = torch.zeros(3,dtype=torch.float, device=DEVICE)\n",
    "\n",
    "    I = ndarray_to_Image(np.hstack((\n",
    "        tensor_to_ndarray(camera.gt_image),\n",
    "        tensor_to_ndarray(model.render(camera, bg=bg))\n",
    "    )))\n",
    "\n",
    "    I.save(os.path.join(out_dir,camera.name))\n",
    "    # rendering.append(I)\n",
    "\n",
    "# rendering[0].save(\n",
    "#     os.path.join(out_dir,\"rendering.gif\"),\n",
    "#     save_all=True,\n",
    "#     append_images=rendering[2::2],\n",
    "#     optimize=False,\n",
    "#     duration=500,\n",
    "#     loop=0,\n",
    "# )\n",
    "\n",
    "print(\"Results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Not working rn\")\n",
    "\n",
    "from scipy.spatial.transform import Slerp,Rotation\n",
    "from src.utils.camera import Camera\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "\n",
    "cameras = sorted(dataset, key=lambda cam:cam.name)[:9:2]\n",
    "\n",
    "rotmats = Rotation.from_matrix([camera.R for camera in cameras])\n",
    "slerp = Slerp(range(len(rotmats)),rotmats)\n",
    "\n",
    "np.interp()\n",
    "\n",
    "times = np.linspace(0,len(cameras)-1.1,20)\n",
    "\n",
    "renders = []\n",
    "\n",
    "for t in T:\n",
    "    tint = int(t)\n",
    "    tfrac = t - tint\n",
    "\n",
    "    c1 = cameras[tint]\n",
    "    c2 = cameras[tint+1]\n",
    "\n",
    "    camera = Camera(\n",
    "        gt_image=None,\n",
    "        R=slerp(t).as_matrix(),\n",
    "        t=tfrac * c1.t + (1-tfrac)*c2.t,\n",
    "        fovx=c1.fovx, fovy=c1.fovy,\n",
    "        H=c1.H, W=c1.W,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    renders.append(ndarray_to_Image(np.hstack((\n",
    "        tensor_to_ndarray(c1.gt_image if tfrac<.5 else c2.gt_image),\n",
    "        tensor_to_ndarray(model.render(camera, bg=bg))\n",
    "    ))))\n",
    "\n",
    "renders[0].save(\n",
    "    os.path.join(out_dir,\"rendering_fancy.gif\"),\n",
    "    save_all=True,\n",
    "    append_images=renders[1:],\n",
    "    optimize=False,\n",
    "    duration=500//60,\n",
    "    loop=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
